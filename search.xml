<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>A Voxel Graph CNN for Object Classification with Event Cameras</title>
    <url>/2022/09/26/A-Voxel-Graph-CNN-for-Object-Classification-with-Event-Cameras/</url>
    <content><![CDATA[<p>A Voxel Graph CNN for Object Classification with Event Cameras论文的阅读</p>
<span id="more"></span>
<h2 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h2><h3 id="Event-camera的特点："><a href="#Event-camera的特点：" class="headerlink" title="Event camera的特点："></a>Event camera的特点：</h3><ol>
<li>low power consumption（低能耗）</li>
<li>high dynamic range（高动态范围）</li>
<li>high temporal resolution（高时间分辨率）</li>
</ol>
<h3 id="问题领域："><a href="#问题领域：" class="headerlink" title="问题领域："></a>问题领域：</h3><p>event-based object classification</p>
<h3 id="一般方法："><a href="#一般方法：" class="headerlink" title="一般方法："></a>一般方法：</h3><p>accumulate sparse events into dense frames and then apply traditional 2D learning methods</p>
<p>优点：</p>
<p>achieve advanced performance</p>
<p>缺点：</p>
<p>1.Introduce redundant information</p>
<p>2.sacrifice the sparsity of event data</p>
<p>3.high computational complexity</p>
<p>4.limit the potential of event cameras on real-life applications</p>
<h3 id="解决的问题（已有问题，非本论文提出）："><a href="#解决的问题（已有问题，非本论文提出）：" class="headerlink" title="解决的问题（已有问题，非本论文提出）："></a>解决的问题（已有问题，非本论文提出）：</h3><p>Balance accuracy and model complexity for event-based classification models</p>
<h3 id="现有解决方案："><a href="#现有解决方案：" class="headerlink" title="现有解决方案："></a>现有解决方案：</h3><ol>
<li><p>migrate learning models initially designed for point clouds to event data</p>
<ol>
<li><p>EventNet</p>
<ul>
<li><p>real-time processing of an asynchronous event stream in a recursive and event-wise manner</p>
</li>
<li><p>优点：</p>
<ol>
<li>make use of the sparseness of the data</li>
<li>real-time performance</li>
</ol>
</li>
</ul>
</li>
<li><p>Space-time Event Clouds</p>
<ul>
<li>adapt PointNet to cater to event clouds for real-time gesture recognition</li>
<li>优点：<ol>
<li>high accuracy</li>
<li>explore space-time sparsity of the event stream data</li>
</ol>
</li>
</ul>
</li>
</ol>
</li>
<li><p>Migrate models from pointnet-like architecture</p>
<ol>
<li>PointNet<ul>
<li>design a novel type of neural network that directly consumes point clouds, which well respects the permutation invariance of points in the input</li>
<li>优点：<ol>
<li>simple but highly efficient and effective</li>
</ol>
</li>
</ul>
</li>
</ol>
</li>
<li><p>Utilize graph neural networks</p>
<ol>
<li><p>Graph-Based Spatial-Temporal Feature Learning</p>
<ul>
<li>utilize residual-graph convolutional neural networks (RG-CNN), for end-to-end learning of  appearance-based features directly from graphs</li>
<li>优点：<ol>
<li>preserve the spatial and temporal coherence of spike events</li>
<li>less computation and memory</li>
</ol>
</li>
</ul>
</li>
<li><p>Learning Visual Motion Segmentation using Event Surfaces</p>
<ul>
<li>convert the event stream into a 3D graph in (x, y, t) space and keep per-event temporal information</li>
<li>优点：<ol>
<li>well performance</li>
</ol>
</li>
</ul>
</li>
</ol>
</li>
</ol>
<h3 id="现有解决方案的共性问题："><a href="#现有解决方案的共性问题：" class="headerlink" title="现有解决方案的共性问题："></a>现有解决方案的共性问题：</h3><ol>
<li>Intuitively, Point-wise input is improper for event-based vision tasks.</li>
<li>These points do well in describing the geometry but fail to accurately extract 2D semantics from the event data.</li>
</ol>
<h3 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work:"></a>Related work:</h3><ul>
<li>Event-based approaches<ul>
<li>frame-based method: integrating event signals into frame-wise 2D representations to directly adopt 2D CNNs for event data.</li>
<li>point-based method:  taking a single event or a set of regional events as input units for feature extraction and aggregation.</li>
</ul>
</li>
</ul>
<h3 id="论文贡献："><a href="#论文贡献：" class="headerlink" title="论文贡献："></a>论文贡献：</h3><p>1.propose a novel voxel-wise representation for event data</p>
<ul>
<li>using voxel-wise vertices rather than previous point-wise inputs to explicitly exploit regional          2D semantics of event streams while keeping the sparsity</li>
</ul>
<p>2.customize a lightweight voxel graph convolutional neural network (EV-VGCNN)</p>
<ul>
<li>proposing a multi-scale feature relational layer (MFRL) to extract spatial and motion cues from     each vertex discriminatively concerning its distances to neighbors.</li>
</ul>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><h3 id="流程图："><a href="#流程图：" class="headerlink" title="流程图："></a>流程图：</h3><p><img src="/2022/09/26/A-Voxel-Graph-CNN-for-Object-Classification-with-Event-Cameras/A Voxel Graph CNN for Object Classification with Event Cameras-1.png" alt="image-20220926202411773"></p>
<h3 id="Graph-Construction——Voxelization"><a href="#Graph-Construction——Voxelization" class="headerlink" title="Graph Construction——Voxelization"></a>Graph Construction——Voxelization</h3><p>Event streams representation:</p>
<p>$\lbrace e_{i} \rbrace=\lbrace x_i,y_i,t_i,p_i \rbrace_N$</p>
<p>Time-dimension normalization:</p>
<p>$\lbrace t_i \rbrace=\frac{\lbrace t_i-t_0 \rbrace_N \times A}{t_{N-1}-t_0}$</p>
<p>spatio-temporal resolution: {H,W,A}</p>
<p>size of each voxel: $v_h, v_w ,v_a$</p>
<p>The resulting voxels in spatio-temporal space is of size:</p>
<p>$H_{voxel}=H/v_h , W_{voxel}=W/v_w  , A_{voxel}=A/v_a  $</p>
<p>the coordinate of i-th vertex $U_i = (x_i^v , y_i^v , t_i^v) $ is with the range of $\lbrace H_{voxel}, W_{voxel}, A_{voxel} \rbrace$</p>
<h3 id="Graph-Construction——Vertex-selection"><a href="#Graph-Construction——Vertex-selection" class="headerlink" title="Graph Construction——Vertex selection"></a>Graph Construction——Vertex selection</h3><p>find N_p vertices with the largest number of event points inside and feed them into the learning system</p>
<h3 id="Graph-Construction——Feature-calculation"><a href="#Graph-Construction——Feature-calculation" class="headerlink" title="Graph Construction——Feature calculation"></a>Graph Construction——Feature calculation</h3><p>$F_i^{2d}(x,y)=\sum\limits_{i}^{N_v}p_i^{in}\delta(x-x_i^{in},y-y_i^{in})t_i^{in}$</p>
<p>$N_v$ denotes the number of events inside the vertex $V_i$</p>
<p>$F_i^{2d}\in \mathbb{R}^{1\times v_h\times v_b}$</p>
<p>Then,$\lbrace F_i \rbrace _{N_p}\in \mathbb{R}^{N_p\times v_h\times v_b}$</p>
<h3 id="EV-VGCNN"><a href="#EV-VGCNN" class="headerlink" title="EV-VGCNN"></a>EV-VGCNN</h3><p><img src="/2022/09/26/A-Voxel-Graph-CNN-for-Object-Classification-with-Event-Cameras/A Voxel Graph CNN for Object Classification with Event Cameras-2.png" alt="image-20220926214002122"></p>
<h3 id="EV-VGCNN——MFRL"><a href="#EV-VGCNN——MFRL" class="headerlink" title="EV-VGCNN——MFRL"></a>EV-VGCNN——MFRL</h3><p><img src="/2022/09/26/A-Voxel-Graph-CNN-for-Object-Classification-with-Event-Cameras/A Voxel Graph CNN for Object Classification with Event Cameras-3.png" alt="image-20220926214026543"></p>
]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>Event Cameras</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/04/26/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <categories>
        <category>博客网站搭建</category>
      </categories>
  </entry>
  <entry>
    <title>使用hexo和next搭建博客</title>
    <url>/2022/04/27/%E4%BD%BF%E7%94%A8hexo%E5%92%8Cnext%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<p>笔者进行学习如何搭建一个属于自己的博客，在网上学习了很多大牛的经验。本文汇总了一些在我搭建过程中对我帮助比较大的网址，介绍了如何使用hexo和next搭建并美化博客。</p>
<span id="more"></span>
<h2 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a>搭建</h2><p><a href="http://blog.woooo.tech/2019/08/18/%E4%BD%BF%E7%94%A8GitHub%E5%92%8CHEXO%E7%9A%84%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B/">使用GitHub和Hexo的博客搭建过程</a></p>
<h2 id="美化"><a href="#美化" class="headerlink" title="美化"></a>美化</h2><p><a href="http://blog.woooo.tech/2019/08/19/%E7%94%A8Next%E7%BE%8E%E5%8C%96-HEXO-GitHub-%E5%8D%9A%E5%AE%A2/">用Next美化博客</a></p>
<p><a href="https://xduqinian.github.io/2022/01/11/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/">一些问题和解决方式</a></p>
<p><a href="https://blog.csdn.net/weixin_48927364/article/details/123295436">添加文章的分类和标签</a></p>
<h2 id="日常使用"><a href="#日常使用" class="headerlink" title="日常使用"></a>日常使用</h2><h3 id="新建文章"><a href="#新建文章" class="headerlink" title="新建文章"></a>新建文章</h3><p>打开博客所在文件夹，右键Git Bash Here</p>
<p>输入·</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo new post &quot;文章名称&quot;</span><br></pre></td></tr></table></figure>
<h3 id="更新到github"><a href="#更新到github" class="headerlink" title="更新到github"></a>更新到github</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g -d</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>博客网站搭建</category>
      </categories>
  </entry>
</search>
